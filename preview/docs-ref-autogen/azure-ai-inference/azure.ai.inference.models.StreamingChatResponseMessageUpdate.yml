### YamlMime:PythonClass
uid: azure.ai.inference.models.StreamingChatResponseMessageUpdate
name: StreamingChatResponseMessageUpdate
fullName: azure.ai.inference.models.StreamingChatResponseMessageUpdate
module: azure.ai.inference.models
inheritances:
- azure.ai.inference._model_base.Model
summary: A representation of a chat message update as received in a streaming response.
constructor:
  syntax: 'StreamingChatResponseMessageUpdate(*args: Any, **kwargs: Any)'
variables:
- description: 'The chat role associated with the message. If present, should always
    be

    ''assistant''. Known values are: "system", "user", "assistant", and "tool".'
  name: role
  types:
  - <xref:str>
  - <xref:azure.ai.inference.models.ChatRole>
- description: The content of the message.
  name: content
  types:
  - <xref:str>
- description: 'The tool calls that must be resolved and have their outputs appended
    to

    subsequent input messages for the chat

    completions request to resolve as configured.'
  name: tool_calls
  types:
  - <xref:list>[<xref:azure.ai.inference.models.StreamingChatResponseToolCallUpdate>]
methods:
- uid: azure.ai.inference.models.StreamingChatResponseMessageUpdate.as_dict
  name: as_dict
  summary: Return a dict that can be JSONify using json.dump.
  signature: 'as_dict(*, exclude_readonly: bool = False) -> Dict[str, Any]'
  keywordOnlyParameters:
  - name: exclude_readonly
    description: Whether to remove the readonly properties.
    types:
    - <xref:bool>
  return:
    description: A dict JSON compatible object
    types:
    - <xref:dict>
- uid: azure.ai.inference.models.StreamingChatResponseMessageUpdate.clear
  name: clear
  signature: clear() -> None
- uid: azure.ai.inference.models.StreamingChatResponseMessageUpdate.copy
  name: copy
  signature: copy() -> Model
- uid: azure.ai.inference.models.StreamingChatResponseMessageUpdate.get
  name: get
  signature: 'get(key: str, default: Any = None) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
    defaultValue: None
- uid: azure.ai.inference.models.StreamingChatResponseMessageUpdate.items
  name: items
  signature: items() -> ItemsView[str, Any]
- uid: azure.ai.inference.models.StreamingChatResponseMessageUpdate.keys
  name: keys
  signature: keys() -> KeysView[str]
- uid: azure.ai.inference.models.StreamingChatResponseMessageUpdate.pop
  name: pop
  signature: 'pop(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.inference.models.StreamingChatResponseMessageUpdate.popitem
  name: popitem
  signature: popitem() -> Tuple[str, Any]
- uid: azure.ai.inference.models.StreamingChatResponseMessageUpdate.setdefault
  name: setdefault
  signature: 'setdefault(key: str, default: ~typing.Any = <object object>) -> Any'
  parameters:
  - name: key
    isRequired: true
  - name: default
- uid: azure.ai.inference.models.StreamingChatResponseMessageUpdate.update
  name: update
  signature: 'update(*args: Any, **kwargs: Any) -> None'
- uid: azure.ai.inference.models.StreamingChatResponseMessageUpdate.values
  name: values
  signature: values() -> ValuesView[Any]
attributes:
- uid: azure.ai.inference.models.StreamingChatResponseMessageUpdate.content
  name: content
  summary: The content of the message.
  signature: 'content: str | None'
- uid: azure.ai.inference.models.StreamingChatResponseMessageUpdate.role
  name: role
  summary: 'The chat role associated with the message. If present, should always be
    ''assistant''. Known

    values are: "system", "user", "assistant", and "tool".'
  signature: 'role: str | _models.ChatRole | None'
- uid: azure.ai.inference.models.StreamingChatResponseMessageUpdate.tool_calls
  name: tool_calls
  summary: 'The tool calls that must be resolved and have their outputs appended to
    subsequent input

    messages for the chat

    completions request to resolve as configured.'
  signature: 'tool_calls: List[_models.StreamingChatResponseToolCallUpdate] | None'
